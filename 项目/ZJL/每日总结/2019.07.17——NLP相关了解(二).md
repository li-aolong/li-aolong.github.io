[TOC]

# NLP相关了解（二）

## 中文关键字提取

主要两种方法，以下介绍关键词提取方法：

1. 关键词分配
2. **关键词提取**

- 基于TF-IDF算法
  - `jieba.analyse.extract_tags()`
- 基于TextRank算法
  - `jieba.analyse.textrank()`
- 基于LDA主题模型
  - 文件加载 -> jieba 分词 -> 去停用词 -> 构建词袋模型 -> LDA 模型训练 -> 结果可视化
- 基于pyhanlp
  - `HanLP.extractKeyword()`

## 文本可视化

- 基于文本内容
  - 基于词频，词汇：词云、分布图、Document Cards等
- 基于文本关系
  - 树状图、节点连接的网络图、力导向图、叠式图和 Word Tree 等
- 基于多层面信息
  - 地理热力图、ThemeRiver、SparkClouds、TextFlow 和基于矩阵视图的情感分析可视化等

## 实践

- 文本分类
  - ![img](7.17——NLP相关了解(二).images/7cb83ee0-7d08-11e8-ab3b-8f5f773d8874)
  - 使用了词袋模型，分别使用了SVM和朴素贝叶斯进行训练
- 文本聚类
  - 使用TF-IDF进行抽取特征，使用K-means进行聚类
- 训练了基于HMM的中文分词器