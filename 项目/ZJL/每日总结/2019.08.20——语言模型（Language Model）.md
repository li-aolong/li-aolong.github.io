# 语言模型（Language Model）

## 简介

- 通过计算该词序列中各词的联合概率分布，来评估句子（词序列）的概率
- 应用：句子生成（如自动摘要、问答系统、机器翻译等）；机器翻译、拼写纠错、音字转换、问答系统、语音识别等应用在得到若干候选之后，然后利用语言模型挑一个尽量靠谱的结果

## 统计语言模型

统计语言模型是一个概率模型，计算一个句子的概率。一个句子的概率，就是语料库中出现这个句子的概率。

![[å¬å¼]](https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D+p%28W%29%26%3Dp%28w_1%5ET%29%3Dp%28w1%2Cw2%2C%5Cdots%2Cw_T%29+%5C%5C%26%3D+p%28w1%29%5Ccdot+p%28w_2%7Cw_1%29%5Ccdot+p%28w_3%7Cw_1%5E2%29%5Ccdots+p%28w_T%7Cw_1%5E%7BT-1%7D%29+%5Cend%7Baligned%7D+%5Cend%7Bequation%7D+%E2%80%A6%E2%80%A6%E2%80%A6%28%E5%BC%8F2.1.1%29)

其中各因子是语言模型的参数，我们需要计算这些概率。

![[å¬å¼]](https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+p%28w_k%7Cw_1%5E%7Bk-1%7D%29%3D%5Cfrac%7Bp%28w_1%5Ek%29%7D%7Bp%28w_1%5E%7Bk-1%7D%29%7D+%5Capprox+%5Cfrac%7Bcount%28w_1%5Ek%29%7D%7Bcount%28w_1%5E%7Bk-1%7D%29%7D+%5Clabel%7Beq%3A2%7D%5Cend%7Bequation%7D%E2%80%A6%E2%80%A6%28%E5%BC%8F2.1.2%29%5C%5C%28%E5%BD%93%E8%AF%AD%E6%96%99%E5%BA%93%E5%A4%9F%E5%A4%A7%E6%97%B6%2C%E6%A0%B9%E6%8D%AE%E5%A4%A7%E6%95%B0%E5%AE%9A%E7%90%86%E5%8F%AF%E5%BE%97%29+)

- **缺点**：模型参数过多
- **解释**：假设语料库中词典大小为N，那么一维参数M个，二维参数N^2^个，N维有N^N^个。如果要计算任意长度为T的句子的概率，理论上就需要个 (N+N^2^+...+n^N^)个参数
- **改进**：N-gram模型

## 数据稀疏问题与平滑技术

大规模数据统计方法与有限的训练语料之间必然产生数据稀疏问题，导致零概率问题。

- Add-one（Laplace） Smoothing
  - ![[å¬å¼]](https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+p%28w_k%7Cw_1%5E%7Bk-1%7D%29%26%5Capprox+p%28w_k%7Cw_%7Bk-n%2B1%7D%5E%7Bk-1%7D%29+%5C%5C%26+%5Capprox+%5Cfrac%7Bcount%28w_1%5Ek%29%2B1%7D%7Bcount%28w_%7Bk-n%2B1%7D%5E%7Bk-1%7D%29%2BV%7D+%5C%5C%26%28%E5%88%86%E5%AD%90%E5%A4%9A%E5%8A%A0%E4%BA%861%EF%BC%8C%E5%88%86%E6%AF%8D%E5%A4%9A%E5%8A%A0%E4%BA%86V%EF%BC%8CV%E6%98%AF%E6%89%80%E6%9C%89Ngram%E7%9A%84%E4%B8%AA%E6%95%B0%29+%5Cend%7Baligned%7D+%E2%80%A6%E2%80%A6%28%E5%BC%8F2.3.1%29)
- Good-Turing Smoothing
  - 基本思想是利用频率的类别信息对频率进行平滑
- Interpolation Smoothing
  - 基本思想是将高阶模型和低阶模型作线性组合，利用低元 n-gram 模型对高元 n-gram 模型进行线性插值
- Katz Backoff
  - 基本思想是如果 n-gram 出现频率为 0，就回退到(n-1)-gram 近似求解
- Web-scale LMs

数据平滑技术是构造高鲁棒性语言模型的重要手段，且数据平滑的效果与训练语料库的规模有关。训练语料库规模越小，数据平滑的效果越显著；训练语料库规模越大，数据平滑的效果越不显著。

## 语言模型评估

- **实用方法**：通过看该模型在实际应用（如机器翻译、拼写检查等）中的表现，优点是直观实用，缺点是缺乏针对性、不够直观
- **理论方法**：迷惑度/困惑度/混乱度（preplexity），其基本思想是给测试集赋予较高概率值的语言模型较好

## 小结

- 统计语言模型是一个概率模型，用来计算一个句子的概率
- 当语料库足够大的时候，用统计概率表示语言模型的参数，但是参数过多，很不实用。为了减少参数，基于马尔科夫假设提出N-Gram模型
- 针对数据稀疏问题，提出各种平滑技术
- 对于语言模型的评价，用 Perplexity