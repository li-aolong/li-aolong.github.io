[TOC]

# 使用tensorflow实现Seq2Seq模型

**最基础的Seq2Seq模型**包含了三个部分，即Encoder、Decoder以及连接两者的中间状态向量，Encoder通过学习输入，将其编码成一个固定大小的状态向量S，继而将S传给Decoder，Decoder再通过对状态向量S的学习来进行输出。

![image.png](https://i.loli.net/2019/08/13/TQWFPnAOzE1ifKs.png)

图中每一个box代表了一个RNN单元，通常是LSTM或者GRU。

基础的Seq2Seq是有很多弊端的，首先Encoder将输入编码为固定大小状态向量的过程实际上是一个信息“信息有损压缩”的过程，如果信息量越大，那么这个转化向量的过程对信息的损失就越大，同时，随着sequence length的增加，意味着时间维度上的序列很长，RNN模型也会出现梯度弥散。最后，基础的模型连接Encoder和Decoder模块的组件仅仅是一个固定大小的状态向量，这使得Decoder无法直接去关注到输入信息的更多细节。

基础的Seq2Seq主要包括**Encoder，Decoder，以及连接两者的固定大小的State Vector。**

## 1 数据集

包括source与target：

- source_data: 每一行是一个单词

- target_data: 每一行是经过字母排序后的“单词”，它的每一行与source_data中每一行一一对应

> 如，source_data的第一行是hello，第二行是what，那么target_data中对应的第一行是ehllo，第二行是ahtw。

## 2 数据预处理

加入以下四种字符，`<PAD>`主要用来进行字符补全，`<EOS>`和`<GO>`都是用在Decoder端的序列中，告诉解码器句子的起始与结束，`<UNK>`则用来替代一些未出现过的词或者低频词。

将原始数据转换为数字，这里即为index：

```
['bsaqq', 'npy', 'lbwuj', 'bqv', 'kial'] ==> [7, 25, 13, 20, 24]
```

## 3 模型构建

### 3.1 Encoder

模型构建主要包括Encoder层与Decoder层。在Encoder层，我们首先需要对定义输入的tensor，同时要对字母进行Embedding，再输入到RNN层。

在这里，我们使用TensorFlow中的`tf.contrib.layers.embed_sequence`来对输入进行embedding。

### 3.2 Decoder

#### 3.2.1 target数据处理

将target中的序列作为输入给Decoder端的RNN时，序列中的最后一个字母（或单词）其实是没有用的，因此需要将target中的最后一个字符去掉，同时还需要在前面添加`<go>`标识，告诉模型这代表一个句子的开始。

使用`tf.strided_slice()`来进行这一步处理。

#### 3.2.2 构造Decoder

- 对target数据进行embedding
- 构造Decoder端的RNN单元
- 构造输出层，从而得到每个时间序列上的预测结果
- 构造training decoder
- 构造predicting decoder

### 3.3 连接模块与训练

- 构建好了Encoder层与Decoder以后，将它们连接起来构建Seq2Seq模型
- 定义超参数，loss function、optimizer，batch函数，gradient clipping
- 接下来我们对模型进行训练，定义了batch_size=128，epochs=60。训练loss如下：

![image.png](https://i.loli.net/2019/08/13/B3zfyulxFUk4ZVm.png)

- 进行测试：

![image.png](https://i.loli.net/2019/08/13/MqWHAmlt7feEUVS.png)

## 4 总结

实现了一个基本的序列到序列模型，Encoder通过对输入序列的学习，将学习到的信息转化为一个状态向量传递给Decoder，Decoder再基于这个输入得到输出。

其对短序列的输出还是比较准确的，但一旦输入序列过长，比如15甚至20个字母的单词，其Decoder端的输出就非常的差。