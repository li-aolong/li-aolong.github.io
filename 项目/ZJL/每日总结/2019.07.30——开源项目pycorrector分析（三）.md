[TOC]

# 开源项目*pycorrector*分析（三）

## 基于深度模型的方法——seq2seq

1. 数据预处理
   - `config.py`文件提供了初始化配置
   - 使用`preprocess.py`文件进行处理，同样对CGED三年的比赛数据进行解析，其中90%作为训练集，10%作为测试集，得到：`train.txt`和`test.txxt`
2. 模型
   - 由`seq2seq_model.py`文件构造模型，其中包含了如下特征：
     - **基于attention的seq2seq框架**：其编码器和解码器可以是LSTM或GRU
     - **Pointer-generator网络**：参考论文：<https://arxiv.org/pdf/1704.04368.pdf>
     - **权重共享机制**：使用权重分配机制可以减少参数来提高性能
     - **Beam搜索算法**：实现了一种高效的搜索算法
     - **未知单词替换**：该算法可以与任何基于attention的seq2seq模型一起使用
3. 训练
   - `train.py`文件
     - 将语料中所有出现5次以上的字符与数字一一对应，得到一个字典
     - 初始化一个LSTM模型，使用Adam进行优化
     - `data_reader.py`文件进行数据读取
   - 训练数据，并保存模型
4. `infer.py`文件使用训练好的模型进行测试